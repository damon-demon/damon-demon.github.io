<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yimeng(Damon) Zhang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="links\YimengZhang_CV.pdf">CV</a></div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
<div class="menu-item"><a href="https://damon19950223.github.io">Activities</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yimeng(Damon) Zhang</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://www.instagram.com/damondemon88888/"><img src="happy.jpg" alt="alt text" width="414px" height="310px" /></a>&nbsp;</td>
<td align="left"><p>PhD Candidate (Computer Science),<br /> <a href="https://www.cse.msu.edu">Computer Science and Engineering Department</a>, <br /><a href="https://msu.edu">Michigan State University (MSU)</a><br />
428 S. Shaw Lane <br />
East Lansing, MI, USA <br /> 
E-Mail: zhan1853@msu.edu</p>
</td></tr></table>
<h2>About me</h2>
<p><a href="https://www.instagram.com/damondemon88888/">I</a> received the B.Eng. degree in Electrical and Electronic Engineering (EEE) from <a href="https://www.sheffield.ac.uk/eee">The University of Sheffield, UK</a>, in 2018, and M.Sc. degrees in Electrical Engineering (EE) from <a href="https://www.ee.columbia.edu">Columbia University, USA</a>, in 2020. Currently, I am a PhD Candidate in Computer Science under the supervision of 
<a href="https://lsjxjtu.github.io">Prof. Sijia Liu</a>.</p>
<h2>Research Focuses</h2>
<p>My research centers on enhancing the efficiency of machine learning from multiple perspectives, including data optimization, model architecture, and parameter-efficient fine-tuning techniques. I aim to improve both the training and inference processes by reducing computational and resource demands while maintaining or enhancing performance. A key aspect of my work also involves ensuring model safety, with a focus on robustness against adversarial attacks. By integrating efficiency and safety, my research strives to create scalable, reliable, and secure AI systems that perform effectively in diverse real-world applications. </p>
<ul>
<li><p><b>Deep Learning</b>: Computer Vision (generative models, multi-modality), AI Safety (adversarial attack &amp; defense)</p>
</li>
<li><p><b>Optimization</b>: Zeroth-Order Optimization, Dataset/Model pruning</p>
</li>
</ul>
<h3>Recent Publications</h3>
<p>(* represents equal contribution) <a href="links\Yimeng_Research_Summary_OPTML_MSU.pdf">[Research Summary]</a></p>
<ol>
<li><p><b>Y. Zhang</b>, T. Zhi, J. Liu, S. Sang, L. Jiang, Q. Yan, S. Liu, L. Luo, <a href="https://byteaigc.github.io/ID-Patch/">ID-Patch: Robust ID Association for Group Photo Personalization</a> <a href="https://arxiv.org/abs/2411.13632">[Paper]</a> <a href="links\ID_Patch_Presentation.pdf">[Slide]</a></p>
</li>
<li><p><b>Y. Zhang</b>, X. Chen, J. Jia, Y. Zhang, C. Fan, J. Liu, M. Hong, K. Ding, S. Liu, <a href="https://arxiv.org/abs/2405.15234">Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</a>, <i>NeurIPS&rsquo;24</i> <a href="https://github.com/OPTML-Group/AdvUnlearn">[Code]</a> <a href="https://huggingface.co/OPTML-Group/AdvUnlearn">[HF Model]</a> <a href="https://huggingface.co/spaces/Intel/AdvUnlearn">[Demo]</a> <a href="links\NeurIPS2024_AdvUnlearn_Presentation.pdf">[Slide]</a></p>
</li>
<li><p><b> Y. Zhang* </b>, J. Jia*, X. Chen, A. Chen, Y. Zhang, J. Liu, K. Ding, S. Liu, <a href="https://www.optml-group.com/posts/mu_attack">To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images &hellip; For Now</a>, <i>ECCV&rsquo;24</i> <a href="https://github.com/OPTML-Group/Diffusion-MU-Attack">[Code]</a> <a href="https://huggingface.co/spaces/Intel/UnlearnDiffAtk">[Demo]</a> <a href="links\ECCV24_UnlearnDiffAtk_poster.pdf">[Poster]</a>  <a href="https://huggingface.co/spaces/Intel/UnlearnDiffAtk-Benchmark">[Unlearned DM Benchmark]</a> <a href="links\ECCV2024_UnlearnDiffAtk_Presentation.pdf">[Slide]</a></p>
</li>
<li><p>Y. Zhang, C. Fan, <b>Y. Zhang</b>, Y. Yao, J. Jia, J. Liu, X. Liu, S. Liu, <a href="https://arxiv.org/abs/2402.11846">UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models</a>, <i>NeurIPS&rsquo;24</i> <a href="https://github.com/OPTML-Group/UnlearnCanvas">[Code]</a> <a href="https://huggingface.co/spaces/OPTML-Group/UnlearnCanvas-Benchmark">[Benchmark]</a> <a href="https://huggingface.co/datasets/OPTML-Group/UnlearnCanvas">[Dataset]</a></p>
</li>
<li><p>J. Jia, Y. Zhang, <b>Y. Zhang</b>, J. Liu, B. Runwal, J. Diffenderfer, B. Kailkhura, S. Liu, <a href="https://arxiv.org/abs/2404.18239">SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning</a>, <i>EMNLP&rsquo;24</i> <a href="https://github.com/OPTML-Group/SOUL">[Code]</a></p>
</li>
<li><p>Y. Zhang*, P. Li*, J. Hong*, J. Li, <b>Y. Zhang</b>, W. Zheng, P.-Y. Chen, J. D. Lee, W. Yin, M. Hong, Z. Wang, S. Liu, T. Chen, <a href="https://arxiv.org/abs/2402.11592">Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning: A Benchmark</a>, <i>ICML&rsquo;24</i> <a href="https://github.com/ZO-Bench/ZO-LLM?tab=readme-ov-file">[Code]</a></p>
</li>
<li><p>A. Chen*, <b> Y. Zhang* </b>, J. Jia, J. Diffenderfer, J. Liu, K. Parasyris, Y. Zhang, Z. Zhang, B. Kailkhura, S. Liu, <a href="https://www.optml-group.com/posts/deepzero_iclr24">DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training</a>, <i>ICLR&rsquo;24</i> <a href="https://github.com/OPTML-Group/DeepZero">[Code]</a> <a href="links\ICLR2024_DeepZero_Presentation.pdf">[Slide]</a> <a href="links\ICLR2024_DeepZero_poster.pdf">[Poster]</a></p>
</li>
<li><p>M. Jafari, <b> Y. Zhang </b>, Y. Zhang, S. Liu, <a href="https://arxiv.org/abs/2403.12166">The power of few: accelerating and enhancing data reweighting with coreset selection</a>, <i>ICASSP&rsquo;24</i></p>
</li>
<li><p>Y. Zhang*, <b> Y. Zhang* </b>, A. Chen*,  J. Jia, J. Liu, G. Liu, M. Hong, S. Chang, S. Liu, <a href="https://pruning.netlify.app">Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning</a>, <i>NeurIPS&rsquo;23</i> <a href="https://arxiv.org/abs/2310.08782">[Paper]</a> <a href="https://github.com/OPTML-Group/DP4TL">[Code]</a> <a href="links\NeurIPS'23_dp4tl_poster.pdf">[Poster]</a> <a href="links\NeurIPS2023_DP4TL_presentation.pdf">[Slide]</a></p>
</li>
<li><p><b> Y. Zhang </b>, X. Chen, J. Jia, S. Liu, K. Ding, <a href="https://www.optml-group.com/posts/2dtvp_cvpr23">Text-Visual Prompting for Efficient 2D Temporal Video Grounding</a>, <i>CVPR&rsquo;23</i> <a href="https://github.com/intel/TVP">[Code]</a> <a href="https://huggingface.co/docs/transformers/main/en/model_doc/tvp">[HF Model]</a> <a href="links\2DTVP_CVPR23_poster.pdf">[Poster]</a> <a href="links\CVPR23_2D_TVP_presentation.pdf">[Slide]</a> </p>
</li>
<li><p><b> Y. Zhang* </b>, A.K. Kamath*, Q. Wu*, Z. Fan*, W. Chen, Z. Wang, S. Chang, S. Liu, C. Hao, <a href="https://arxiv.org/abs/2210.08578">Data-Model-Circuit Tri-Design for Ultra-Light Video Intelligence on Edge Devices</a>, <i>ASP-DAC&rsquo;23</i> <a href="links\ASPDAC2023_TriDesign_Presentation.pdf">[Slide]</a></p>
</li>
<li><p><b>Y. Zhang</b>, Y. Yao, J. Jia, J. Yi,  M. Hong, S. Chang, S. Liu, <a href="https://openreview.net/forum?id=W9G_ImpHlQd">How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective</a>, <i>ICLR&rsquo;22</i>  <tt>(Spotlight, acceptance rate 5%)</tt> <a href="https://github.com/damon-demon/Black-Box-Defense">[Code]</a> <a href="links\ICLR22_BlackBox_Defense_Poster.png">[Poster]</a> <a href="links\ICLR2022_ZO_AE_DS_Presentation.pdf">[Slide]</a></p>
</li>
<li><p>Y. Gong, Y. Yao, Y. Li, <b> Y. Zhang</b>, X. Liu, X. Lin, S. Liu, <a href="https://openreview.net/forum?id=gpp7cf0xdfN">Reverse Engineering of Imperceptible Adversarial Image Perturbations</a>, <i>ICLR&rsquo;22</i>  <a href="https://github.com/Yifanfanfanfan/Reverse-Engineering-of-Imperceptible-Adversarial-Image-Perturbations">[Code]</a></p>
</li>
<li><p><b>Y. Zhang</b>,X. Y. Liu,  B. Wu, A. Walid, <a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413527">Video Synthesis via Transform-Based Tensor Neural Network</a>, ACM International Conference on Multimedia <i>(ACM MM&rsquo;20)</i></p>
</li>
<li><p>X. Han, B. Wu, Z. Shou, X. Y. Liu, <b>Y. Zhang</b>, L. Kong, <a href="https://ojs.aaai.org//index.php/AAAI/article/view/6726">Tensor FISTA-Net for real-time snapshot compressive imaging</a>, AAAI Conference on Artificial Intelligence <i>(AAAI&rsquo;20)</i></p>
</li>
</ol>
<p><a href="https://scholar.google.com/citations?user=eWcAggoAAAAJ&amp;hl">Full list of publications</a>.
<br /></p>
</td>
</tr>
</table>
</body>
</html>
